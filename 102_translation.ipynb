{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5af5906-2fb9-4316-b906-1e3fa5092f6c",
   "metadata": {},
   "source": [
    "# 翻訳比較\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b5ecbf1d-b301-49d2-90c3-8f60499f8cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# セル2: 必要なライブラリのインポート\n",
    "import anthropic\n",
    "import cohere\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "#import pandas as pd\n",
    "#import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "#from typing import Dict, List\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3bb620c3-24da-4017-b691-2f6cd384d17d",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "CLAUDE_API_KEY = os.getenv(\"CLAUDE_APIKEY\")\n",
    "COHERE_API_KEY = os.getenv(\"COHERE_APIKEY\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_APIKEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8abd2962-3581-4e07-9c75-de899f56ee6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "translation_query = lambda text: f\"\"\"以下の英語テキストを日本語に翻訳してください。\n",
    "翻訳は自然で流暢な日本語にし、原文のニュアンスと意味を正確に保ってください。\n",
    "   \n",
    "英語テキスト:\n",
    "{text}\n",
    "\n",
    "日本語翻訳:\"\"\"\n",
    "\n",
    "summarization_query = lambda text: f\"\"\"以下のテキストを日本語で400字程度に要約してください。\n",
    "翻訳は自然で流暢な日本語にし、原文のニュアンスと意味を正確に保ってください。\n",
    "   \n",
    "オリジナルテキスト:\n",
    "{text}\n",
    "\n",
    "日本語要約:\"\"\"\n",
    "\n",
    "class ClaudeClient:\n",
    "    def __init__(self, api_key):\n",
    "        self.client = anthropic.Anthropic(api_key=api_key)\n",
    "\n",
    "    def translate(self, text: str, model: str = \"claude-sonnet-4-5\") -> Dict:\n",
    "        start_time = time.time()\n",
    "    \n",
    "        try:\n",
    "            message = self.client.messages.create(\n",
    "                model=model,\n",
    "                max_tokens=4096,\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": translation_query(text)\n",
    "                    }\n",
    "                ]\n",
    "            )\n",
    "            \n",
    "            translation = message.content[0].text\n",
    "            elapsed_time = time.time() - start_time\n",
    "            \n",
    "            return {\n",
    "                \"translation\": translation,\n",
    "                \"time\": elapsed_time,\n",
    "                \"model\": model,\n",
    "                \"success\": True,\n",
    "                \"error\": None\n",
    "            }\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                \"translation\": None,\n",
    "                \"time\": time.time() - start_time,\n",
    "                \"model\": model,\n",
    "                \"success\": False,\n",
    "                \"error\": str(e)\n",
    "            }\n",
    "\n",
    "    def summarize(self, text: str, model: str = \"claude-sonnet-4-5\") -> Dict:\n",
    "        start_time = time.time()\n",
    "    \n",
    "        try:\n",
    "            message = self.client.messages.create(\n",
    "                model=model,\n",
    "                max_tokens=4096,\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": summarization_query(text)\n",
    "                    }\n",
    "                ]\n",
    "            )\n",
    "            \n",
    "            translation = message.content[0].text\n",
    "            elapsed_time = time.time() - start_time\n",
    "            \n",
    "            return {\n",
    "                \"translation\": translation,\n",
    "                \"time\": elapsed_time,\n",
    "                \"model\": model,\n",
    "                \"success\": True,\n",
    "                \"error\": None\n",
    "            }\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                \"translation\": None,\n",
    "                \"time\": time.time() - start_time,\n",
    "                \"model\": model,\n",
    "                \"success\": False,\n",
    "                \"error\": str(e)\n",
    "            }\n",
    "\n",
    "\n",
    "class CohereClient:\n",
    "    def __init__(self, api_key):\n",
    "        self.client = cohere.Client(api_key=api_key)\n",
    "\n",
    "    def translate(self, text: str, model: str = \"command-a-translate-08-2025\") -> Dict:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            response = self.client.chat(\n",
    "                model=model,\n",
    "                message=translation_query(text),\n",
    "                temperature=0.3\n",
    "            )\n",
    "            \n",
    "            translation = response.text\n",
    "            elapsed_time = time.time() - start_time\n",
    "            \n",
    "            return {\n",
    "                \"translation\": translation,\n",
    "                \"time\": elapsed_time,\n",
    "                \"model\": model,\n",
    "                \"success\": True,\n",
    "                \"error\": None\n",
    "            }\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                \"translation\": None,\n",
    "                \"time\": time.time() - start_time,\n",
    "                \"model\": model,\n",
    "                \"success\": False,\n",
    "                \"error\": str(e)\n",
    "            }\n",
    "            \n",
    "    def summarize(self, text: str, model: str = \"command-a-03-2025\") -> Dict:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            response = self.client.chat(\n",
    "                model=model,\n",
    "                message=summarization_query(text),\n",
    "                temperature=0.3\n",
    "            )\n",
    "            \n",
    "            translation = response.text\n",
    "            elapsed_time = time.time() - start_time\n",
    "            \n",
    "            return {\n",
    "                \"translation\": translation,\n",
    "                \"time\": elapsed_time,\n",
    "                \"model\": model,\n",
    "                \"success\": True,\n",
    "                \"error\": None\n",
    "            }\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                \"translation\": None,\n",
    "                \"time\": time.time() - start_time,\n",
    "                \"model\": model,\n",
    "                \"success\": False,\n",
    "                \"error\": str(e)\n",
    "            }\n",
    "\n",
    "class OpenAIClient:\n",
    "    def __init__(self, api_key):\n",
    "        self.client = OpenAI(api_key=api_key)\n",
    "\n",
    "    def translate(self, text: str, model: str = \"gpt-4o\") -> Dict:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"system\",\n",
    "                        \"content\": \"あなたは優秀な翻訳者です。英語を自然で流暢な日本語に翻訳してください。\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": translation_query(text)\n",
    "                    }\n",
    "                ],\n",
    "                temperature=0.3\n",
    "            )\n",
    "            \n",
    "            translation = response.choices[0].message.content\n",
    "            elapsed_time = time.time() - start_time\n",
    "            \n",
    "            return {\n",
    "                \"translation\": translation,\n",
    "                \"time\": elapsed_time,\n",
    "                \"model\": model,\n",
    "                \"success\": True,\n",
    "                \"error\": None\n",
    "            }\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                \"translation\": None,\n",
    "                \"time\": time.time() - start_time,\n",
    "                \"model\": model,\n",
    "                \"success\": False,\n",
    "                \"error\": str(e)\n",
    "            }\n",
    "\n",
    "    def summarize(self, text: str, model: str = \"gpt-4o\") -> Dict:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"system\",\n",
    "                        \"content\": \"あなたは優秀な編集者です。自然で流暢な日本語に要約してください。\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": summarization_query(text)\n",
    "                    }\n",
    "                ],\n",
    "                temperature=0.3\n",
    "            )\n",
    "            \n",
    "            translation = response.choices[0].message.content\n",
    "            elapsed_time = time.time() - start_time\n",
    "            \n",
    "            return {\n",
    "                \"translation\": translation,\n",
    "                \"time\": elapsed_time,\n",
    "                \"model\": model,\n",
    "                \"success\": True,\n",
    "                \"error\": None\n",
    "            }\n",
    "        except Exception as e:\n",
    "            return {\n",
    "                \"translation\": None,\n",
    "                \"time\": time.time() - start_time,\n",
    "                \"model\": model,\n",
    "                \"success\": False,\n",
    "                \"error\": str(e)\n",
    "            }\n",
    "\n",
    "\n",
    "\n",
    "claude_client = ClaudeClient(CLAUDE_API_KEY)\n",
    "cohere_client = CohereClient(COHERE_API_KEY)\n",
    "openai_client = OpenAIClient(OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "d3467703-f0ca-4696-9636-e413f63ff466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"translation\": \"**AI法の4項目要約**\\n\\nAI法はリスクに応じてAIを分類しています。受容できないリスク（社会信用スコアシステムや操作的AIなど）は禁止されます。法律の大部分は規制対象となる高リスクAIシステムに関するもので、限定的リスクのAIシステム（チャットボットやディープフェイクなど）には軽度の透明性義務が課され、開発者と利用者はエンドユーザーがAIと対話していることを認識させる必要があります。最小リスク（ゲームやスパムフィルターなど）は規制対象外です。\\n\\n義務の大半は高リスクAIシステムの提供者（開発者）に課されます。これはEU内外を問わず、EU市場で提供する事業者や、出力結果がEU内で使用される第三国の事業者も含みます。利用者（導入者）にも一部義務がありますが、開発者より少なくなっています。\\n\\n汎用AI（GPAI）については、全ての提供者が技術文書の提供、著作権指令の遵守、訓練データの概要公開を行う必要があります。オープンライセンスの提供者は著作権遵守と訓練データ概要の公開のみで済みますが、システミックリスクを呈する全てのGPAIモデル提供者は、モデル評価、敵対的テスト、インシデント報告、サイバーセキュリティ保護も実施する必要があります。\",\n",
      "  \"time\": 10.314465999603271,\n",
      "  \"model\": \"claude-sonnet-4-5\",\n",
      "  \"success\": true,\n",
      "  \"error\": null\n",
      "}\n",
      "{\n",
      "  \"translation\": \"EUのAI法は、AIをリスクに応じて分類し、以下の4つのポイントにまとめられる。  \\n1. **容認できないリスク**（例：社会スコアリングや操作的なAI）は禁止される。  \\n2. **高リスクAI**が主な規制対象で、提供者（開発者）に多くの義務が課される。EU内での使用や提供を予定する者、および第三国で開発されたがEU内で出力が利用されるAIも含まれる。  \\n3. **限定的なリスクAI**（例：チャットボットやディープフェイク）は透明性義務が軽減され、ユーザーがAIと対話していることを認識できるよう措置が求められる。  \\n4. **最小リスクAI**（例：ビデオゲームやスパムフィルター）は規制対象外だが、生成AIの台頭で状況は変化している。  \\nまた、**汎用AI（GPAI）**については、すべての提供者が技術文書や使用説明書の提出、著作権指令の遵守、トレーニングデータの概要公開が義務付けられる。ただし、自由でオープンなライセンスのGPAIは、システムリスクがない限り著作権遵守とデータ概要公開のみでよい。システムリスクのあるGPAI提供者は、モデル評価や敵対的テスト、重大インシデントの追跡・報告、サイバーセキュリティ確保も必須となる。\",\n",
      "  \"time\": 5.798414945602417,\n",
      "  \"model\": \"command-a-03-2025\",\n",
      "  \"success\": true,\n",
      "  \"error\": null\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "Four-point summary\n",
    "The AI Act classifies AI according to its risk:\n",
    "Unacceptable risk is prohibited (e.g. social scoring systems and manipulative AI).\n",
    "Most of the text addresses high-risk AI systems, which are regulated.\n",
    "A smaller section handles limited risk AI systems, subject to lighter transparency obligations: developers and deployers must ensure that end-users are aware that they are interacting with AI (chatbots and deepfakes).\n",
    "Minimal risk is unregulated (including the majority of AI applications currently available on the EU single market, such as AI enabled video games and spam filters – at least in 2021; this is changing with generative AI).\n",
    "The majority of obligations fall on providers (developers) of high-risk AI systems.\n",
    "Those that intend to place on the market or put into service high-risk AI systems in the EU, regardless of whether they are based in the EU or a third country.\n",
    "And also third country providers where the high risk AI system’s output is used in the EU.\n",
    "Users are natural or legal persons that deploy an AI system in a professional capacity, not affected end-users.\n",
    "Users (deployers) of high-risk AI systems have some obligations, though less than providers (developers).\n",
    "This applies to users located in the EU, and third country users where the AI system’s output is used in the EU.\n",
    "General purpose AI (GPAI):\n",
    "All GPAI model providers must provide technical documentation, instructions for use, comply with the Copyright Directive, and publish a summary about the content used for training.\n",
    "Free and open licence GPAI model providers only need to comply with copyright and publish the training data summary, unless they present a systemic risk.\n",
    "All providers of GPAI models that present a systemic risk – open or closed – must also conduct model evaluations, adversarial testing, track and report serious incidents and ensure cybersecurity protections.\n",
    "\"\"\"\n",
    "\n",
    "print(json.dumps(claude_client.summarize(text), indent=2, ensure_ascii=False))\n",
    "print(json.dumps(cohere_client.summarize(text), indent=2, ensure_ascii=False))\n",
    "#print(openai_client.summarize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c69ee34-bf43-4b6a-a0f3-17393f64d025",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
